# nn-experiments

working of activation functions i,e sigmoid,tanh,relu and softmax to train neural networks
